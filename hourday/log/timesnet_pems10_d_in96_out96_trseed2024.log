Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=4, c_out=107, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems10_d.csv', dec_in=107, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=107, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='TimesNet', model_id='pems10_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=2, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems10_d_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4087
val 517
test 1127
	iters: 100, epoch: 1 | loss: 0.5597699
	speed: 1.4537s/iter; left time: 2824.4755s
	iters: 200, epoch: 1 | loss: 0.4349092
	speed: 1.5102s/iter; left time: 2783.3321s
	iters: 300, epoch: 1 | loss: 0.4327720
	speed: 1.5411s/iter; left time: 2686.1183s
	iters: 400, epoch: 1 | loss: 0.7790244
	speed: 1.5331s/iter; left time: 2518.9055s
	iters: 500, epoch: 1 | loss: 0.3876877
	speed: 1.5271s/iter; left time: 2356.3341s
	iters: 600, epoch: 1 | loss: 0.3962310
	speed: 1.5368s/iter; left time: 2217.5840s
	iters: 700, epoch: 1 | loss: 0.3133655
	speed: 1.5451s/iter; left time: 2075.0944s
	iters: 800, epoch: 1 | loss: 0.1759704
	speed: 1.5397s/iter; left time: 1913.7911s
	iters: 900, epoch: 1 | loss: 0.2596726
	speed: 1.5404s/iter; left time: 1760.7125s
	iters: 1000, epoch: 1 | loss: 0.2208211
	speed: 1.5348s/iter; left time: 1600.7644s
Epoch: 1 cost time: 1559.2953341007233
Epoch: 1, Steps: 1021 | Train Loss: 0.4015912 Vali Loss: 1.6108067 Test Loss: 1.2402189
Validation loss decreased (inf --> 1.610807).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2634654
	speed: 7.4010s/iter; left time: 6823.7134s
	iters: 200, epoch: 2 | loss: 0.2725068
	speed: 1.5311s/iter; left time: 1258.5808s
	iters: 300, epoch: 2 | loss: 0.2296291
	speed: 1.4979s/iter; left time: 1081.5027s
	iters: 400, epoch: 2 | loss: 0.1483231
	speed: 1.4548s/iter; left time: 904.9031s
	iters: 500, epoch: 2 | loss: 0.2240521
	speed: 1.4473s/iter; left time: 755.5093s
	iters: 600, epoch: 2 | loss: 0.1972285
	speed: 1.4338s/iter; left time: 605.0558s
	iters: 700, epoch: 2 | loss: 0.1288304
	speed: 1.4533s/iter; left time: 467.9678s
	iters: 800, epoch: 2 | loss: 0.1455069
	speed: 1.4675s/iter; left time: 325.7933s
	iters: 900, epoch: 2 | loss: 0.2180613
	speed: 1.4536s/iter; left time: 177.3375s
	iters: 1000, epoch: 2 | loss: 0.2355935
	speed: 1.4612s/iter; left time: 32.1456s
Epoch: 2 cost time: 1503.6062245368958
Epoch: 2, Steps: 1021 | Train Loss: 0.2427925 Vali Loss: 1.6138351 Test Loss: 1.2569804
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
>>>>>>>testing : long_term_forecast_pems10_d_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1127
test shape: (1127, 1, 96, 107) (1127, 1, 96, 107)
test shape: (1127, 96, 107) (1127, 96, 107)
mse:1.2402188777923584, mae:0.6782365441322327
>>>>>>>Overall time: 4663 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=4, c_out=107, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems10_d.csv', dec_in=107, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=107, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='TimesNet', model_id='pems10_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=2, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems10_d_96_192_TimesNet_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3991
val 421
test 1031
	iters: 100, epoch: 1 | loss: 0.6195663
	speed: 1.8860s/iter; left time: 3573.9178s
	iters: 200, epoch: 1 | loss: 0.6512175
	speed: 1.8976s/iter; left time: 3406.2066s
	iters: 300, epoch: 1 | loss: 0.4741764
	speed: 1.8523s/iter; left time: 3139.6046s
	iters: 400, epoch: 1 | loss: 0.4436682
	speed: 1.8926s/iter; left time: 3018.7488s
	iters: 500, epoch: 1 | loss: 0.5483882
	speed: 1.8483s/iter; left time: 2763.2801s
	iters: 600, epoch: 1 | loss: 0.3558000
	speed: 1.8754s/iter; left time: 2616.2466s
	iters: 700, epoch: 1 | loss: 0.4181842
	speed: 1.9057s/iter; left time: 2467.8838s
	iters: 800, epoch: 1 | loss: 0.3056099
	speed: 1.8771s/iter; left time: 2243.1600s
	iters: 900, epoch: 1 | loss: 0.2882729
	speed: 1.8695s/iter; left time: 2047.1440s
Epoch: 1 cost time: 1870.8984949588776
Epoch: 1, Steps: 997 | Train Loss: 0.4957821 Vali Loss: 2.0008397 Test Loss: 1.4403852
Validation loss decreased (inf --> 2.000840).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3990259
	speed: 8.2162s/iter; left time: 7378.1682s
	iters: 200, epoch: 2 | loss: 0.3759892
	speed: 1.8204s/iter; left time: 1452.6851s
	iters: 300, epoch: 2 | loss: 0.4289172
	speed: 1.8372s/iter; left time: 1282.3906s
	iters: 400, epoch: 2 | loss: 0.4410920
	speed: 1.8436s/iter; left time: 1102.4449s
	iters: 500, epoch: 2 | loss: 0.2113112
	speed: 1.8259s/iter; left time: 909.3105s
	iters: 600, epoch: 2 | loss: 0.1969338
	speed: 1.8131s/iter; left time: 721.6234s
	iters: 700, epoch: 2 | loss: 0.2049791
	speed: 1.8045s/iter; left time: 537.7555s
	iters: 800, epoch: 2 | loss: 0.2135208
	speed: 1.8055s/iter; left time: 357.4969s
	iters: 900, epoch: 2 | loss: 0.2473975
	speed: 1.7945s/iter; left time: 175.8620s
Epoch: 2 cost time: 1814.1896724700928
Epoch: 2, Steps: 997 | Train Loss: 0.2810942 Vali Loss: 2.0527198 Test Loss: 1.4565140
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
>>>>>>>testing : long_term_forecast_pems10_d_96_192_TimesNet_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1031
test shape: (1031, 1, 192, 107) (1031, 1, 192, 107)
test shape: (1031, 192, 107) (1031, 192, 107)
mse:1.4403852224349976, mae:0.735725998878479
>>>>>>>Overall time: 4996 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=4, c_out=107, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems10_d.csv', dec_in=107, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=107, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='TimesNet', model_id='pems10_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=2, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems10_d_96_336_TimesNet_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3847
val 277
test 887
	iters: 100, epoch: 1 | loss: 0.6475568
	speed: 2.1321s/iter; left time: 3886.7703s
	iters: 200, epoch: 1 | loss: 0.6903130
	speed: 2.0376s/iter; left time: 3510.8254s
	iters: 300, epoch: 1 | loss: 0.5002873
	speed: 2.0338s/iter; left time: 3300.8095s
	iters: 400, epoch: 1 | loss: 0.6693740
	speed: 2.0837s/iter; left time: 3173.4835s
	iters: 500, epoch: 1 | loss: 0.4638397
	speed: 2.1042s/iter; left time: 2994.2157s
	iters: 600, epoch: 1 | loss: 0.4931291
	speed: 2.1027s/iter; left time: 2781.8995s
	iters: 700, epoch: 1 | loss: 0.5155578
	speed: 2.1057s/iter; left time: 2575.3313s
	iters: 800, epoch: 1 | loss: 0.2891373
	speed: 2.1041s/iter; left time: 2362.9547s
	iters: 900, epoch: 1 | loss: 0.4592139
	speed: 2.1285s/iter; left time: 2177.4455s
Epoch: 1 cost time: 2014.512516260147
Epoch: 1, Steps: 961 | Train Loss: 0.5538762 Vali Loss: 2.2723763 Test Loss: 1.7740023
Validation loss decreased (inf --> 2.272376).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3403585
	speed: 8.1329s/iter; left time: 7010.5313s
	iters: 200, epoch: 2 | loss: 0.2723300
	speed: 2.1498s/iter; left time: 1638.1402s
	iters: 300, epoch: 2 | loss: 0.4511612
	speed: 2.1535s/iter; left time: 1425.6366s
	iters: 400, epoch: 2 | loss: 0.4054008
	speed: 2.1599s/iter; left time: 1213.8690s
	iters: 500, epoch: 2 | loss: 0.2052540
	speed: 2.1612s/iter; left time: 998.4871s
	iters: 600, epoch: 2 | loss: 0.5190266
	speed: 2.1639s/iter; left time: 783.3280s
	iters: 700, epoch: 2 | loss: 0.2514793
	speed: 2.1690s/iter; left time: 568.2873s
	iters: 800, epoch: 2 | loss: 0.2295383
	speed: 2.1770s/iter; left time: 352.6768s
	iters: 900, epoch: 2 | loss: 0.2218275
	speed: 2.1813s/iter; left time: 135.2416s
Epoch: 2 cost time: 2078.7462227344513
Epoch: 2, Steps: 961 | Train Loss: 0.3097848 Vali Loss: 2.3847876 Test Loss: 1.8181119
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
>>>>>>>testing : long_term_forecast_pems10_d_96_336_TimesNet_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 887
test shape: (887, 1, 336, 107) (887, 1, 336, 107)
test shape: (887, 336, 107) (887, 336, 107)
mse:1.7740024328231812, mae:0.8511019349098206
>>>>>>>Overall time: 5455 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=4, c_out=107, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems10_d.csv', dec_in=107, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=107, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='TimesNet', model_id='pems10_d_96_720', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=720, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=2, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems10_d_96_720_TimesNet_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3463
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 85, in train
    vali_data, vali_loader = self._get_data(flag='val')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 85, in data_provider
    print(flag, len(data_set))
ValueError: __len__() should return >= 0
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=4, c_out=107, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems10_d.csv', dec_in=107, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=107, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='TimesNet', model_id='pems10_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=2, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems10_d_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4087
val 517
test 1127
	iters: 100, epoch: 1 | loss: 0.5597680
	speed: 1.4384s/iter; left time: 2794.9012s
	iters: 200, epoch: 1 | loss: 0.4349088
	speed: 1.4947s/iter; left time: 2754.7590s
	iters: 300, epoch: 1 | loss: 0.4327434
	speed: 1.5235s/iter; left time: 2655.4284s
	iters: 400, epoch: 1 | loss: 0.7795197
	speed: 1.5214s/iter; left time: 2499.7379s
	iters: 500, epoch: 1 | loss: 0.3997584
	speed: 1.5188s/iter; left time: 2343.4561s
	iters: 600, epoch: 1 | loss: 0.3719285
	speed: 1.5000s/iter; left time: 2164.4736s
	iters: 700, epoch: 1 | loss: 0.3147674
	speed: 1.4115s/iter; left time: 1895.6234s
	iters: 800, epoch: 1 | loss: 0.1735436
	speed: 1.4150s/iter; left time: 1758.8114s
	iters: 900, epoch: 1 | loss: 0.2626868
	speed: 1.4247s/iter; left time: 1628.4422s
	iters: 1000, epoch: 1 | loss: 0.2210522
	speed: 1.4379s/iter; left time: 1499.7249s
Epoch: 1 cost time: 1499.8764724731445
Epoch: 1, Steps: 1021 | Train Loss: 0.3991805 Vali Loss: 1.5881321 Test Loss: 1.2398113
Validation loss decreased (inf --> 1.588132).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2512186
	speed: 7.2229s/iter; left time: 6659.4726s
	iters: 200, epoch: 2 | loss: 0.2653959
	speed: 1.4385s/iter; left time: 1182.4166s
	iters: 300, epoch: 2 | loss: 0.2221612
	speed: 1.4598s/iter; left time: 1053.9856s
	iters: 400, epoch: 2 | loss: 0.1497396
	speed: 1.4155s/iter; left time: 880.4597s
	iters: 500, epoch: 2 | loss: 0.2258604
	speed: 1.4353s/iter; left time: 749.2397s
	iters: 600, epoch: 2 | loss: 0.1994040
	speed: 1.4471s/iter; left time: 610.6883s
	iters: 700, epoch: 2 | loss: 0.1201190
	speed: 1.4517s/iter; left time: 467.4547s
	iters: 800, epoch: 2 | loss: 0.1436657
	speed: 1.4473s/iter; left time: 321.2916s
	iters: 900, epoch: 2 | loss: 0.2138092
	speed: 1.4293s/iter; left time: 174.3706s
	iters: 1000, epoch: 2 | loss: 0.2415109
	speed: 1.4425s/iter; left time: 31.7345s
Epoch: 2 cost time: 1470.918134689331
Epoch: 2, Steps: 1021 | Train Loss: 0.2353595 Vali Loss: 1.6104438 Test Loss: 1.2397729
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
>>>>>>>testing : long_term_forecast_pems10_d_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1127
test shape: (1127, 1, 96, 107) (1127, 1, 96, 107)
test shape: (1127, 96, 107) (1127, 96, 107)
mse:1.2398114204406738, mae:0.6756099462509155
>>>>>>>Overall time: 4544 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=4, c_out=107, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems10_d.csv', dec_in=107, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=107, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='TimesNet', model_id='pems10_d_96_192', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=192, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=2, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems10_d_96_192_TimesNet_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3991
val 421
test 1031
	iters: 100, epoch: 1 | loss: 0.6195660
	speed: 1.8588s/iter; left time: 3522.4471s
	iters: 200, epoch: 1 | loss: 0.6512154
	speed: 1.8733s/iter; left time: 3362.5435s
	iters: 300, epoch: 1 | loss: 0.4741732
	speed: 1.8272s/iter; left time: 3097.1313s
	iters: 400, epoch: 1 | loss: 0.4427328
	speed: 1.8663s/iter; left time: 2976.7728s
	iters: 500, epoch: 1 | loss: 0.5654727
	speed: 1.8304s/iter; left time: 2736.3946s
	iters: 600, epoch: 1 | loss: 0.3475320
	speed: 1.8447s/iter; left time: 2573.3885s
	iters: 700, epoch: 1 | loss: 0.4410827
	speed: 1.8528s/iter; left time: 2399.4253s
	iters: 800, epoch: 1 | loss: 0.2991019
	speed: 1.8273s/iter; left time: 2183.6668s
	iters: 900, epoch: 1 | loss: 0.2849757
	speed: 1.8305s/iter; left time: 2004.3813s
Epoch: 1 cost time: 1838.0440797805786
Epoch: 1, Steps: 997 | Train Loss: 0.4958735 Vali Loss: 2.0027809 Test Loss: 1.4254097
Validation loss decreased (inf --> 2.002781).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4013678
	speed: 8.0881s/iter; left time: 7263.0710s
	iters: 200, epoch: 2 | loss: 0.3630067
	speed: 1.8117s/iter; left time: 1445.7195s
	iters: 300, epoch: 2 | loss: 0.3806019
	speed: 1.7966s/iter; left time: 1254.0149s
	iters: 400, epoch: 2 | loss: 0.4301315
	speed: 1.8080s/iter; left time: 1081.2128s
	iters: 500, epoch: 2 | loss: 0.2073000
	speed: 1.7825s/iter; left time: 887.6948s
	iters: 600, epoch: 2 | loss: 0.1988932
	speed: 1.7695s/iter; left time: 704.2775s
	iters: 700, epoch: 2 | loss: 0.2036802
	speed: 1.7693s/iter; left time: 527.2582s
	iters: 800, epoch: 2 | loss: 0.2174447
	speed: 1.7745s/iter; left time: 351.3525s
	iters: 900, epoch: 2 | loss: 0.2528774
	speed: 1.7635s/iter; left time: 172.8242s
Epoch: 2 cost time: 1779.7418174743652
Epoch: 2, Steps: 997 | Train Loss: 0.2806058 Vali Loss: 2.0593374 Test Loss: 1.4580230
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
>>>>>>>testing : long_term_forecast_pems10_d_96_192_TimesNet_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1031
test shape: (1031, 1, 192, 107) (1031, 1, 192, 107)
test shape: (1031, 192, 107) (1031, 192, 107)
mse:1.4254114627838135, mae:0.7283487915992737
>>>>>>>Overall time: 4919 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=4, c_out=107, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems10_d.csv', dec_in=107, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=107, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='TimesNet', model_id='pems10_d_96_336', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=336, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=2, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems10_d_96_336_TimesNet_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3847
val 277
test 887
	iters: 100, epoch: 1 | loss: 0.6488837
	speed: 2.0913s/iter; left time: 3812.4741s
	iters: 200, epoch: 1 | loss: 0.6897569
	speed: 2.0024s/iter; left time: 3450.1646s
	iters: 300, epoch: 1 | loss: 0.4966756
	speed: 2.0000s/iter; left time: 3246.0465s
	iters: 400, epoch: 1 | loss: 0.6646785
	speed: 2.0672s/iter; left time: 3148.2860s
	iters: 500, epoch: 1 | loss: 0.4591131
	speed: 2.0498s/iter; left time: 2916.8745s
	iters: 600, epoch: 1 | loss: 0.5170410
	speed: 2.0655s/iter; left time: 2732.7160s
	iters: 700, epoch: 1 | loss: 0.5141745
	speed: 2.0666s/iter; left time: 2527.4256s
	iters: 800, epoch: 1 | loss: 0.2891550
	speed: 2.0646s/iter; left time: 2318.5880s
	iters: 900, epoch: 1 | loss: 0.4618183
	speed: 2.0687s/iter; left time: 2116.2450s
Epoch: 1 cost time: 1975.201426744461
Epoch: 1, Steps: 961 | Train Loss: 0.5584812 Vali Loss: 2.2718079 Test Loss: 1.7656457
Validation loss decreased (inf --> 2.271808).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3263789
	speed: 7.8617s/iter; left time: 6776.7975s
	iters: 200, epoch: 2 | loss: 0.2935934
	speed: 2.0861s/iter; left time: 1589.6256s
	iters: 300, epoch: 2 | loss: 0.4741335
	speed: 2.0827s/iter; left time: 1378.7766s
	iters: 400, epoch: 2 | loss: 0.4183477
	speed: 2.0865s/iter; left time: 1172.6178s
	iters: 500, epoch: 2 | loss: 0.2192972
	speed: 2.1005s/iter; left time: 970.4527s
	iters: 600, epoch: 2 | loss: 0.5631424
	speed: 2.1074s/iter; left time: 762.8961s
	iters: 700, epoch: 2 | loss: 0.2481535
	speed: 2.1181s/iter; left time: 554.9485s
	iters: 800, epoch: 2 | loss: 0.2265490
	speed: 2.1196s/iter; left time: 343.3716s
	iters: 900, epoch: 2 | loss: 0.2328226
	speed: 2.1242s/iter; left time: 131.7024s
Epoch: 2 cost time: 2019.8440527915955
Epoch: 2, Steps: 961 | Train Loss: 0.3135193 Vali Loss: 2.3183975 Test Loss: 1.8385713
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
>>>>>>>testing : long_term_forecast_pems10_d_96_336_TimesNet_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 887
test shape: (887, 1, 336, 107) (887, 1, 336, 107)
test shape: (887, 336, 107) (887, 336, 107)
mse:1.765647053718567, mae:0.8430202007293701
>>>>>>>Overall time: 5324 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=4, c_out=107, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems10_d.csv', dec_in=107, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=107, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='TimesNet', model_id='pems10_d_96_720', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=720, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=2, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems10_d_96_720_TimesNet_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3463
Traceback (most recent call last):
  File "run.py", line 158, in <module>
    exp.train(setting)
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 85, in train
    vali_data, vali_loader = self._get_data(flag='val')
  File "/g/data/hn98/du/exlts/hourdayweek/exp/exp_long_term_forecasting.py", line 31, in _get_data
    data_set, data_loader = data_provider(self.args, flag)
  File "/g/data/hn98/du/exlts/hourdayweek/data_provider/data_factory.py", line 85, in data_provider
    print(flag, len(data_set))
ValueError: __len__() should return >= 0
Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=4, c_out=107, checkpoints='./checkpoints/', d_ff=512, d_layers=1, d_model=512, data='custom', data_path='pems10_d.csv', dec_in=107, des='Exp', devices='0,1,2,3', distil=True, dropout=0, e_layers=2, embed='timeF', enc_in=107, factor=3, features='M', freq='h', gap_day=365, gpu=0, inverse=False, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='TimesNet', model_id='pems10_d_96_96', moving_avg=25, n_heads=8, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patience=3, pred_len=96, root_path='../../data/pems/', samle_rate=1.0, sample_seed=7, seasonal_patterns='Monthly', seq_len=96, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=2, train_seed=2024, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_pems10_d_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4087
val 517
test 1127
	iters: 100, epoch: 1 | loss: 0.5597687
	speed: 1.4409s/iter; left time: 2799.6570s
	iters: 200, epoch: 1 | loss: 0.4349092
	speed: 1.4991s/iter; left time: 2762.8101s
	iters: 300, epoch: 1 | loss: 0.4327596
	speed: 1.5291s/iter; left time: 2665.2994s
	iters: 400, epoch: 1 | loss: 0.7794989
	speed: 1.5273s/iter; left time: 2509.4015s
	iters: 500, epoch: 1 | loss: 0.3995898
	speed: 1.5222s/iter; left time: 2348.7841s
	iters: 600, epoch: 1 | loss: 0.3477165
	speed: 1.5255s/iter; left time: 2201.3630s
	iters: 700, epoch: 1 | loss: 0.2984318
	speed: 1.5268s/iter; left time: 2050.5502s
	iters: 800, epoch: 1 | loss: 0.1705377
	speed: 1.5265s/iter; left time: 1897.3870s
	iters: 900, epoch: 1 | loss: 0.2633928
	speed: 1.5171s/iter; left time: 1734.0926s
	iters: 1000, epoch: 1 | loss: 0.2300228
	speed: 1.5203s/iter; left time: 1585.6740s
Epoch: 1 cost time: 1546.1890177726746
Epoch: 1, Steps: 1021 | Train Loss: 0.3991162 Vali Loss: 1.5742184 Test Loss: 1.2323277
Validation loss decreased (inf --> 1.574218).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2587934
	speed: 7.3874s/iter; left time: 6811.2129s
	iters: 200, epoch: 2 | loss: 0.2545844
	speed: 1.5146s/iter; left time: 1245.0071s
	iters: 300, epoch: 2 | loss: 0.2281042
	speed: 1.5035s/iter; left time: 1085.5396s
	iters: 400, epoch: 2 | loss: 0.1487820
	speed: 1.4788s/iter; left time: 919.8014s
	iters: 500, epoch: 2 | loss: 0.2234275
	speed: 1.4770s/iter; left time: 770.9690s
	iters: 600, epoch: 2 | loss: 0.1916132
	speed: 1.4786s/iter; left time: 623.9715s
	iters: 700, epoch: 2 | loss: 0.1268053
	speed: 1.4717s/iter; left time: 473.8898s
	iters: 800, epoch: 2 | loss: 0.1454823
	speed: 1.4635s/iter; left time: 324.8970s
	iters: 900, epoch: 2 | loss: 0.2083762
	speed: 1.4540s/iter; left time: 177.3886s
	iters: 1000, epoch: 2 | loss: 0.2202007
	speed: 1.4619s/iter; left time: 32.1610s
Epoch: 2 cost time: 1513.4897243976593
Epoch: 2, Steps: 1021 | Train Loss: 0.2351527 Vali Loss: 1.6628069 Test Loss: 1.2743491
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
>>>>>>>testing : long_term_forecast_pems10_d_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_fc3_ebtimeF_dtTrue_srate1.0_sseed7_trainseed2024_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1127
test shape: (1127, 1, 96, 107) (1127, 1, 96, 107)
test shape: (1127, 96, 107) (1127, 96, 107)
mse:1.232326626777649, mae:0.6715931296348572
>>>>>>>Overall time: 4650 seconds<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
